from funasr import AutoModel
import numpy as np
import soundfile
import io
from typing import Dict, Any, Optional
import uuid
import logging

logger = logging.getLogger(__name__)

class ASRService:
    def __init__(self):
        """åˆå§‹åŒ–ASRæœåŠ¡ - åªä½¿ç”¨ paraformer-zh-streaming"""
        # æµå¼é…ç½®
        self.chunk_size = [0, 10, 5]  # 600mså»¶è¿Ÿ
        self.encoder_chunk_look_back = 4
        self.decoder_chunk_look_back = 1
        
        # è®¡ç®—æ ‡å‡† chunk å¤§å°
        self.chunk_stride = self.chunk_size[1] * 960  # 9600 é‡‡æ ·ç‚¹ = 600ms @ 16kHz
        
        # åŠ è½½æ¨¡å‹
        logger.info("æ­£åœ¨åŠ è½½ paraformer-zh-streaming æ¨¡å‹...")
        self.model = AutoModel(model="/etc/nginx/html/demo/models/paraformer-zh-streaming")
        logger.info("æ¨¡å‹åŠ è½½å®Œæˆ!")
        logger.info(f"æ ‡å‡† chunk å¤§å°: {self.chunk_stride} é‡‡æ ·ç‚¹ (600ms)")
        
        # ä¼šè¯ç®¡ç†
        self.sessions = {}
        
        # ç»Ÿè®¡
        self.stats = {"total_requests": 0, "active_sessions": 0}
    
    def is_ready(self) -> bool:
        """æ£€æŸ¥æœåŠ¡æ˜¯å¦å°±ç»ª"""
        return self.model is not None
    
    def create_session(self) -> str:
        """
        åˆ›å»ºæ–°çš„è¯†åˆ«ä¼šè¯
        
        Returns:
            ä¼šè¯ID
        """
        session_id = str(uuid.uuid4())
        self.sessions[session_id] = {
            "cache": {},
            "accumulated_text": "",
            "chunk_count": 0,
            "audio_buffer": np.array([], dtype=np.float32)  # éŸ³é¢‘ç¼“å†²åŒº
        }
        
        self.stats["active_sessions"] = len(self.sessions)
        logger.info(f"åˆ›å»ºä¼šè¯: {session_id}")
        return session_id
    
    def process_chunk(self, session_id: str, audio_chunk: np.ndarray) -> Optional[Dict[str, Any]]:
        """
        å¤„ç†éŸ³é¢‘å—ï¼ˆæµå¼è¯†åˆ«ï¼‰
        
        Args:
            session_id: ä¼šè¯ID
            audio_chunk: éŸ³é¢‘æ•°æ® (float32, 16kHz)
            
        Returns:
            è¯†åˆ«ç»“æœå­—å…¸ï¼Œå¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°æ–‡å­—è¿”å› None
        """
        if session_id not in self.sessions:
            raise ValueError(f"æ— æ•ˆçš„ä¼šè¯ID: {session_id}")
        
        session = self.sessions[session_id]
        
        # è·³è¿‡å¤ªçŸ­çš„éŸ³é¢‘
        if len(audio_chunk) < 100:
            return None
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šç¼“å†²éŸ³é¢‘ç›´åˆ°è¾¾åˆ°æ ‡å‡† chunk å¤§å°
        session["audio_buffer"] = np.concatenate([session["audio_buffer"], audio_chunk])
        
        # å¦‚æœç¼“å†²åŒºä¸å¤Ÿä¸€ä¸ªå®Œæ•´ chunkï¼Œç»§ç»­ç­‰å¾…
        if len(session["audio_buffer"]) < self.chunk_stride:
            logger.debug(f"ç¼“å†²ä¸­: {len(session['audio_buffer'])}/{self.chunk_stride}")
            return None
        
        # å–å‡ºä¸€ä¸ªå®Œæ•´ chunk
        speech_chunk = session["audio_buffer"][:self.chunk_stride]
        session["audio_buffer"] = session["audio_buffer"][self.chunk_stride:]  # ä¿ç•™å‰©ä½™
        
        logger.debug(f"å¤„ç† chunk: {len(speech_chunk)} é‡‡æ ·ç‚¹, å‰©ä½™: {len(session['audio_buffer'])}")
        
        try:
            # æµå¼è¯†åˆ«ï¼ˆæŒ‰ç…§å®˜æ–¹ç¤ºä¾‹ï¼‰
            res = self.model.generate(
                input=speech_chunk,
                cache=session["cache"],
                is_final=False,
                chunk_size=self.chunk_size,
                encoder_chunk_look_back=self.encoder_chunk_look_back,
                decoder_chunk_look_back=self.decoder_chunk_look_back
            )
            
            print(f"\n{'='*60}")
            print(f"ğŸ” æ¨¡å‹åŸå§‹è¿”å›: {res}")
            
            # æå–è¯†åˆ«ç»“æœ
            if res and len(res) > 0:
                text = res[0].get("text", "")
                
                print(f"ğŸ“ æå–æ–‡æœ¬: [{text}]")
                print(f"ğŸ“š å½“å‰ç´¯ç§¯: [{session['accumulated_text']}]")
                print(f"{'='*60}\n")
                
                logger.info(f"ğŸ” æ¨¡å‹åŸå§‹è¿”å›: {res}")
                logger.info(f"ğŸ“ æå–æ–‡æœ¬: [{text}]")
                logger.info(f"ğŸ“š å½“å‰ç´¯ç§¯: [{session['accumulated_text']}]")
                
                if text:
                    # ğŸ”§ ä¿®å¤ï¼šæ¯ä¸ªchunkè¿”å›çš„æ˜¯ç‹¬ç«‹ç‰‡æ®µï¼Œç›´æ¥è¿½åŠ 
                    new_text = text
                    
                    # æ›´æ–°ç´¯ç§¯æ–‡æœ¬ï¼ˆç›´æ¥æ‹¼æ¥ï¼‰
                    session["accumulated_text"] += text
                    session["chunk_count"] += 1
                    
                    logger.info(f"âœ… è¯†åˆ«ç¬¬ {session['chunk_count']} å—: ç‰‡æ®µ=[{text}], ç´¯ç§¯=[{session['accumulated_text']}]")
                    
                    return {
                        "current_text": new_text,  # æœ¬æ¬¡çš„æ–‡å­—ç‰‡æ®µ
                        "accumulated_text": session["accumulated_text"],  # å®Œæ•´çš„ç´¯ç§¯æ–‡å­—
                        "chunk_count": session["chunk_count"]
                    }
                else:
                    logger.debug(f"æœ¬è½®æ— æ–‡æœ¬è¿”å›")
        
        except Exception as e:
            logger.error(f"è¯†åˆ«é”™è¯¯: {e}", exc_info=True)
            raise
        
        return None
    
    def finalize_session(self, session_id: str, final_chunk: Optional[np.ndarray] = None) -> str:
        """
        ç»“æŸä¼šè¯ï¼Œè·å–æœ€ç»ˆç»“æœ
        
        Args:
            session_id: ä¼šè¯ID
            final_chunk: æœ€åä¸€å—éŸ³é¢‘ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            å®Œæ•´çš„è¯†åˆ«æ–‡æœ¬
        """
        if session_id not in self.sessions:
            return ""
        
        session = self.sessions[session_id]
        
        # å¤„ç†ç¼“å†²åŒºä¸­å‰©ä½™çš„éŸ³é¢‘
        if len(session["audio_buffer"]) > 0:
            logger.info(f"å¤„ç†å‰©ä½™éŸ³é¢‘: {len(session['audio_buffer'])} é‡‡æ ·ç‚¹")
            
            try:
                res = self.model.generate(
                    input=session["audio_buffer"],
                    cache=session["cache"],
                    is_final=True,  # æ ‡è®°ä¸ºæœ€åä¸€å—
                    chunk_size=self.chunk_size,
                    encoder_chunk_look_back=self.encoder_chunk_look_back,
                    decoder_chunk_look_back=self.decoder_chunk_look_back
                )
                
                if res and len(res) > 0:
                    text = res[0].get("text", "")
                    if text:
                        session["accumulated_text"] = text
                        logger.info(f"ğŸ”š æœ€ç»ˆæ–‡æœ¬: [{text}]")
            
            except Exception as e:
                logger.error(f"æœ€ç»ˆå—å¤„ç†é”™è¯¯: {e}", exc_info=True)
        
        result = session["accumulated_text"]
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats["total_requests"] += 1
        
        logger.info(f"â¹ï¸  ä¼šè¯ç»“æŸ: {session_id}, æœ€ç»ˆè¯†åˆ«: [{result}]")
        
        return result
    
    def cleanup_session(self, session_id: str):
        """æ¸…ç†ä¼šè¯"""
        if session_id in self.sessions:
            del self.sessions[session_id]
            self.stats["active_sessions"] = len(self.sessions)
            logger.info(f"ğŸ§¹ æ¸…ç†ä¼šè¯: {session_id}")
    
    def recognize_file(self, audio_bytes: bytes) -> Dict[str, Any]:
        """
        è¯†åˆ«å®Œæ•´éŸ³é¢‘æ–‡ä»¶ï¼ˆåˆ†å—æµå¼å¤„ç†ï¼‰
        
        Args:
            audio_bytes: éŸ³é¢‘æ–‡ä»¶å­—èŠ‚
            
        Returns:
            è¯†åˆ«ç»“æœ
        """
        # è¯»å–éŸ³é¢‘
        audio_data, sample_rate = soundfile.read(io.BytesIO(audio_bytes))
        
        if sample_rate != 16000:
            raise ValueError(f"éŸ³é¢‘é‡‡æ ·ç‡å¿…é¡»ä¸º16kHzï¼Œå½“å‰ä¸º{sample_rate}Hz")
        
        # æŒ‰ç…§å®˜æ–¹ç¤ºä¾‹åˆ†å—å¤„ç†
        cache = {}
        results = []
        
        total_chunk_num = int(len(audio_data - 1) / self.chunk_stride + 1)
        
        for i in range(total_chunk_num):
            speech_chunk = audio_data[i * self.chunk_stride : (i + 1) * self.chunk_stride]
            is_final = (i == total_chunk_num - 1)
            
            res = self.model.generate(
                input=speech_chunk,
                cache=cache,
                is_final=is_final,
                chunk_size=self.chunk_size,
                encoder_chunk_look_back=self.encoder_chunk_look_back,
                decoder_chunk_look_back=self.decoder_chunk_look_back
            )
            
            if res and len(res) > 0:
                text = res[0].get("text", "")
                if text:
                    results.append(text)
        
        text = "".join(results)
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats["total_requests"] += 1
        
        return {
            "text": text,
            "duration": len(audio_data) / sample_rate
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_requests": self.stats["total_requests"],
            "active_sessions": self.stats["active_sessions"]
        }